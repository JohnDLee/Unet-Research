{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff1b9f5ef50>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(10), range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving Data\n",
      "Device: cpu\n",
      "Loading DataLoaders\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils.utils_dataset import *\n",
    "from utils.utils_unet import *\n",
    "from utils.utils_training import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "root = '.'\n",
    "\n",
    "# Retrieve data and include transformation operations\n",
    "print('Retrieving Data')\n",
    "\n",
    "train_path_images = root + '/datasets/training/images'\n",
    "train_path_target = root + '/datasets/training/1st_manual'\n",
    "train_path_mask = root + '/datasets/training/mask'\n",
    "test_path = root + '/datasets/test/images'\n",
    "\n",
    "# transformations\n",
    "\n",
    "# alternative using Random Operations function\n",
    "'''\n",
    "train_transform = transforms.Compose([RandomOperations([RandomHorizontalFlip(p = 1),\n",
    "                                                        RandomVerticalFlip(p = 1)],\n",
    "                                                       weights = [.5, .5]),\n",
    "                                      RandomRotate(degrees = 180),\n",
    "                                      ToTensor()])\n",
    "'''\n",
    "train_transform = transforms.Compose([RandomHorizontalFlip(p = .5),\n",
    "                                     RandomVerticalFlip(p = .5),\n",
    "                                     RandomRotate(degrees = 180),\n",
    "                                     ToTensor()])\n",
    "\n",
    "test_transform = ToTensor()\n",
    "\n",
    "# retrieve dataset\n",
    "train_dataset = CustomDataset(image_root=train_path_images,\n",
    "                              target_root=train_path_target,\n",
    "                              mask_root=train_path_mask,\n",
    "                              transform=train_transform)\n",
    "test_dataset = CustomDataset(image_root=test_path,\n",
    "                             transform = test_transform)\n",
    "\n",
    "\n",
    "# check if GPU is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = 'cpu'\n",
    "print('Device:', device)\n",
    "\n",
    "\n",
    "# Put data into dataloaders\n",
    "print('Loading DataLoaders')\n",
    "\n",
    "# batch sizes\n",
    "train_batch_size = 1\n",
    "val_batch_size = 1\n",
    "test_batch_size = 1\n",
    "\n",
    "# split into train and val\n",
    "train_size = int(len(train_dataset) * .7)\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_data, val_data = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# load into dataloaders\n",
    "train_loader = DataLoader(train_data, batch_size = train_batch_size, shuffle = False)\n",
    "val_loader = DataLoader(val_data, batch_size = val_batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test_dataset, batch_size = test_batch_size, shuffle = True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up UNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/algo_trade/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a14a1eed834f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m                      \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                      \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                     device = device)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'No Training Validation Loss - {val_loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Unet-Research/Unet_research/utils/utils_training.py\u001b[0m in \u001b[0;36mval_epoch\u001b[0;34m(epoch, network, loss_fn, dataloader, device, use_mask)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mimage_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0msegmentation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# process gt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/algo_trade/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Unet-Research/Unet_research/utils/utils_unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Original:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb1_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0msc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DB1 Conv:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/algo_trade/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/algo_trade/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/algo_trade/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/algo_trade/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/algo_trade/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 440\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set up UNET and Optimizers\n",
    "print('Setting up UNet')\n",
    "unet = UNet(init_channels = 3,\n",
    "            filters = 64,\n",
    "            output_channels = 2,\n",
    "            pool_mode = 'max',\n",
    "            up_mode = 'upconv', \n",
    "            connection = 'cat',\n",
    "            same_padding = True,\n",
    "            use_batchnorm = True,\n",
    "            conv_layers_per_block = 2\n",
    "            )\n",
    "\n",
    "# !!!!! SET UP INITIAL WEIGHTS according to article\n",
    "unet.to(device)\n",
    "\n",
    "# optimizer parameters\n",
    "params = unet.parameters()\n",
    "lr = .01\n",
    "momentum = .99 # according to article\n",
    "optimizer = optim.SGD(params, lr = lr, momentum = momentum )\n",
    "\n",
    "# loss function\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# LR scheduler (for later )\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                                 mode='min',\n",
    "                                                 factor=.1,\n",
    "                                                 patience=5,\n",
    "                                                 verbose=True)\n",
    "\n",
    "# training cycle\n",
    "print('Training')\n",
    "\n",
    "# validate once on random initialization\n",
    "\n",
    "val_loss = val_epoch(epoch=0,\n",
    "                     network=unet,\n",
    "                     loss_fn=loss_fn,\n",
    "                     dataloader=val_loader,\n",
    "                    device = device)\n",
    "print(f'No Training Validation Loss - {val_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 1000\n",
    "values = {'train_loss': [], 'val_loss': []}\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    #train\n",
    "\n",
    "    train_loss = train_epoch(epoch=epoch,\n",
    "                           network=unet,\n",
    "                           optimizer=optimizer,\n",
    "                           loss_fn=loss_fn,\n",
    "                           dataloader=train_loader,\n",
    "                            device = device,\n",
    "                            save_location = './models/')\n",
    "    #validate\n",
    "    val_loss = val_epoch(epoch=0,\n",
    "                     network=unet,\n",
    "                     loss_fn=loss_fn,\n",
    "                     dataloader=val_loader,\n",
    "                    device = device)\n",
    "\n",
    "    #report metrics\n",
    "    print(f'Train Loss: {train_loss}\\nVal Loss: {val_loss}')\n",
    "    values['train_loss'].append(train_loss)\n",
    "    values['val_loss'].append(val_loss)\n",
    "\n",
    "    plot_test_epoch(epoch=epoch,\n",
    "                   network=unet,\n",
    "                   dataloader=test_loader,\n",
    "                   num_cols=2)\n",
    "    # change lr\n",
    "    scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_test_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize = (15, 5))\n",
    "\n",
    "example = enumerate(val_loader)\n",
    "next(example)\n",
    "batch_idx, (example_image, example_gt, example_mask)= next(example)\n",
    "print(example_image.size())\n",
    "fig.suptitle('Train Example 1')\n",
    "ax[0].imshow(transforms.ToPILImage()(example_image[0]))\n",
    "ax[1].imshow(transforms.ToPILImage()(example_gt[0]),cmap = 'gray')\n",
    "ax[2].imshow(transforms.ToPILImage()(example_mask[0]),cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_target(example_gt).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(transforms.ToPILImage()(split_target(example_gt)[0][1]),cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = unet(example_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([example_mask, example_mask], dim = 1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_seg, new_gt = get_masked(seg, split_target(example_gt), example_mask, device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_seg.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gt.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(transforms.ToPILImage()(new_gt[0][1]),cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gt.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.ub1_upsample[0].in_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
