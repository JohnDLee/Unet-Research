{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from utils.utils_dataset import *\n",
    "from utils.utils_unet import *\n",
    "from utils.utils_training import *\n",
    "from utils.utils_debug import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving Data\n",
      "Device: cpu\n",
      "Loading DataLoaders\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "root = '.'\n",
    "\n",
    "# Retrieve data and include transformation operations\n",
    "print('Retrieving Data')\n",
    "\n",
    "train_path_images = root + '/datasets/training/images'\n",
    "train_path_target = root + '/datasets/training/1st_manual'\n",
    "train_path_mask = root + '/datasets/training/mask'\n",
    "test_path = root + '/datasets/test/images'\n",
    "\n",
    "# transformations\n",
    "\n",
    "# alternative using Random Operations function\n",
    "'''\n",
    "train_transform = transforms.Compose([RandomOperations([RandomHorizontalFlip(p = 1),\n",
    "                                                        RandomVerticalFlip(p = 1)],\n",
    "                                                       weights = [.5, .5]),\n",
    "                                      RandomRotate(degrees = 180),\n",
    "                                      ToTensor()])\n",
    "'''\n",
    "train_transform = transforms.Compose([RandomHorizontalFlip(p = .5),\n",
    "                                     RandomVerticalFlip(p = .5),\n",
    "                                     RandomRotate(degrees = 180),\n",
    "                                     ToTensor()])\n",
    "\n",
    "test_transform = ToTensor()\n",
    "\n",
    "# retrieve dataset\n",
    "train_dataset = CustomDataset(image_root=train_path_images,\n",
    "                              target_root=train_path_target,\n",
    "                              mask_root=train_path_mask,\n",
    "                              transform=train_transform)\n",
    "test_dataset = CustomDataset(image_root=test_path,\n",
    "                             transform = test_transform)\n",
    "\n",
    "\n",
    "# check if GPU is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', device)\n",
    "\n",
    "\n",
    "# Put data into dataloaders\n",
    "print('Loading DataLoaders')\n",
    "\n",
    "# batch sizes\n",
    "train_batch_size = 1\n",
    "val_batch_size = 1\n",
    "test_batch_size = 1\n",
    "\n",
    "# split into train and val\n",
    "train_size = int(len(train_dataset) * .7)\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_data, val_data = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# load into dataloaders\n",
    "train_loader = DataLoader(train_data, batch_size = train_batch_size, shuffle = False)\n",
    "val_loader = DataLoader(val_data, batch_size = val_batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test_dataset, batch_size = test_batch_size, shuffle = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model2 = UNet(init_channels = 3,\n",
    "            filters = 64,\n",
    "            output_channels = 2,\n",
    "            pool_mode = 'max',\n",
    "            up_mode = 'upconv', \n",
    "            connection = 'cat',\n",
    "            same_padding = True,\n",
    "            use_batchnorm = True,\n",
    "            conv_layers_per_block = 2,\n",
    "\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_model2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = UNet2(init_channels = 3,\n",
    "            filters = 64,\n",
    "            output_channels = 2,\n",
    "            model_depth = 4,\n",
    "            pool_mode = 'max',\n",
    "            up_mode = 'upconv', \n",
    "            connection = 'cat',\n",
    "            same_padding = True,\n",
    "            use_batchnorm = True,\n",
    "            use_dropblock = True,\n",
    "            block_size = 7,\n",
    "            drop_size =\n",
    "            conv_layers_per_block = 2,\n",
    "            activation_fcn = 'leaky_relu'\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 conv:  torch.Size([1, 64, 64, 64])\n",
      "Step 0 pool:  torch.Size([1, 64, 32, 32])\n",
      "Step 1 conv:  torch.Size([1, 128, 32, 32])\n",
      "Step 1 pool:  torch.Size([1, 128, 16, 16])\n",
      "Step 2 conv:  torch.Size([1, 256, 16, 16])\n",
      "Step 2 pool:  torch.Size([1, 256, 8, 8])\n",
      "Step 3 conv:  torch.Size([1, 512, 8, 8])\n",
      "Step 3 pool:  torch.Size([1, 512, 4, 4])\n",
      "Step conn:  torch.Size([1, 1024, 4, 4])\n",
      "Step 0 upsample:  torch.Size([1, 512, 8, 8])\n",
      "Step 0 conv:  torch.Size([1, 512, 8, 8])\n",
      "Step 1 upsample:  torch.Size([1, 256, 16, 16])\n",
      "Step 1 conv:  torch.Size([1, 256, 16, 16])\n",
      "Step 2 upsample:  torch.Size([1, 128, 32, 32])\n",
      "Step 2 conv:  torch.Size([1, 128, 32, 32])\n",
      "Step 3 upsample:  torch.Size([1, 64, 64, 64])\n",
      "Step 3 conv:  torch.Size([1, 64, 64, 64])\n",
      "Step final:  torch.Size([1, 2, 64, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.7424, 0.6314, 0.6183,  ..., 0.4958, 0.6468, 0.5814],\n",
       "          [0.4730, 0.5810, 0.2081,  ..., 0.2814, 0.5695, 0.6351],\n",
       "          [0.6788, 0.4588, 0.4454,  ..., 0.2878, 0.6770, 0.3856],\n",
       "          ...,\n",
       "          [0.5331, 0.5597, 0.5021,  ..., 0.7979, 0.5272, 0.6936],\n",
       "          [0.5906, 0.6075, 0.7990,  ..., 0.6246, 0.5700, 0.5980],\n",
       "          [0.7832, 0.7642, 0.5742,  ..., 0.5212, 0.7053, 0.5347]],\n",
       "\n",
       "         [[0.5621, 0.3302, 0.6416,  ..., 0.3296, 0.7678, 0.3987],\n",
       "          [0.3796, 0.5964, 0.6334,  ..., 0.4138, 0.5334, 0.5892],\n",
       "          [0.6756, 0.2686, 0.8631,  ..., 0.6177, 0.3736, 0.6127],\n",
       "          ...,\n",
       "          [0.3725, 0.3365, 0.5456,  ..., 0.1170, 0.5043, 0.3119],\n",
       "          [0.6738, 0.1470, 0.5873,  ..., 0.3998, 0.5873, 0.5711],\n",
       "          [0.6222, 0.3306, 0.6321,  ..., 0.3301, 0.2856, 0.4152]]]],\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 3, 64, 64)\n",
    "test_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet2(\n",
       "  (_dropblock): DropBlock2D()\n",
       "  (_act_fcn): LeakyReLU(negative_slope=0.01)\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): DropBlock2D()\n",
       "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): LeakyReLU(negative_slope=0.01)\n",
       "        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (5): DropBlock2D()\n",
       "        (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): DropBlock2D()\n",
       "        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): LeakyReLU(negative_slope=0.01)\n",
       "        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (5): DropBlock2D()\n",
       "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): DropBlock2D()\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): LeakyReLU(negative_slope=0.01)\n",
       "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (5): DropBlock2D()\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): DropBlock2D()\n",
       "        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): LeakyReLU(negative_slope=0.01)\n",
       "        (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (5): DropBlock2D()\n",
       "        (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conn_block): Sequential(\n",
       "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (1): DropBlock2D()\n",
       "    (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (5): DropBlock2D()\n",
       "    (6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (up_blocks): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): DropBlock2D()\n",
       "        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): LeakyReLU(negative_slope=0.01)\n",
       "        (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (5): DropBlock2D()\n",
       "        (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): DropBlock2D()\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): LeakyReLU(negative_slope=0.01)\n",
       "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (5): DropBlock2D()\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): DropBlock2D()\n",
       "        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): LeakyReLU(negative_slope=0.01)\n",
       "        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (5): DropBlock2D()\n",
       "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (3): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): DropBlock2D()\n",
       "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): LeakyReLU(negative_slope=0.01)\n",
       "        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (5): DropBlock2D()\n",
       "        (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_conv): Sequential(\n",
       "    (0): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (1): DropBlock2D()\n",
       "    (2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3, -1, -1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in enumerate(test_model.children()):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'trains/trains2/models/epoch500/unet.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = load_model(test_model, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "val_loss = val_epoch_debug(\n",
    "                     network=test_model,\n",
    "                     loss_fn=loss_fn,\n",
    "                     dataloader=val_loader,\n",
    "                     device=device,\n",
    "                     use_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_metrics(network=test_model,\n",
    "                  val_dataloader=val_loader,\n",
    "                  test_dataloader=test_loader,\n",
    "                  train_losses=np.arange(0, 10, .1),\n",
    "                  val_losses=np.arange(0, 20, .2),\n",
    "                    confusion_threshold = .05,\n",
    "                  device=device,\n",
    "                  save=True,\n",
    "                  save_path='./metrics/test3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5, 5) + 1\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.ge(1-.25).count_nonzero()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.ge(1 + .25) & x.lt(2-.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.ModuleList([nn.ModuleList((nn.Sequential(nn.Conv2d(1,1,3)),nn.Sequential(nn.Conv2d(1, 1, 3)))),nn.ModuleList([nn.Sequential(nn.Conv2d(1,1,3)),nn.Sequential(nn.Conv2d(1, 1, 3))])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [None, nn.ReLU()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Sequential(*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
